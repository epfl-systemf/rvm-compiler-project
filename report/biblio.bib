@article{
doi:10.1126/science.aam9744,
author = {Charles E. Leiserson  and Neil C. Thompson  and Joel S. Emer  and Bradley C. Kuszmaul  and Butler W. Lampson  and Daniel Sanchez  and Tao B. Schardl },
title = {There’s plenty of room at the Top: What will drive computer performance after Moore’s law?},
journal = {Science},
volume = {368},
number = {6495},
pages = {eaam9744},
year = {2020},
doi = {10.1126/science.aam9744},
URL = {https://www.science.org/doi/abs/10.1126/science.aam9744},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aam9744},
abstract = {The doubling of the number of transistors on a chip every 2 years, a seemly inevitable trend that has been called Moore's law, has contributed immensely to improvements in computer performance. However, silicon-based transistors cannot get much smaller than they are today, and other approaches should be explored to keep performance growing. Leiserson et al. review recent examples and argue that the most promising place to look is at the top of the computing stack, where improvements in software, algorithms, and hardware architecture can bring the much-needed boost. Science, this issue p. eaam9744 The miniaturization of semiconductor transistors has driven the growth in computer performance for more than 50 years. As miniaturization approaches its limits, bringing an end to Moore’s law, performance gains will need to come from software, algorithms, and hardware. We refer to these technologies as the “Top” of the computing stack to distinguish them from the traditional technologies at the “Bottom”: semiconductor physics and silicon-fabrication technology. In the post-Moore era, the Top will provide substantial performance gains, but these gains will be opportunistic, uneven, and sporadic, and they will suffer from the law of diminishing returns. Big system components offer a promising context for tackling the challenges of working at the Top.}}

@inproceedings{x_heep, title={X-HEEP: An Open-Source, Configurable and Extendible RISC-V Microcontroller}, ISBN={979-8-4007-0140-5}, url={https://infoscience.epfl.ch/handle/20.500.14299/197196}, DOI={10.1145/3587135.3591431}, abstractNote={In this work, we present eXtendible Heterogeneous Energy-Efficient Platform (X-HEEP), a configurable and extendible single-core RISC-V-based ultra-low-power microcontroller. X-HEEP can be used standalone as a low-cost microcontroller, or it can be integrated into existing platforms to act like a peripheral subsystem, or it can be extended and customized with external peripherals and accelerators.}, publisher={New York}, author={Schiavone, Pasquale Davide and Machetti, Simone and Peon Quiros, Miguel and Miranda Calero, José Angel and Denkinger, Benoît Walter and Müller, Christoph Thomas and Rodríguez Álvarez, Rubén and Nasturzio, Saverio and Atienza Alonso, David}, year={2023}, month={may}, pages={379–380}, journal={Proceedings Of The 20Th Acm International Conference On Computing Frontiers 2023, Cf 2023} }


@article{tvm,
  author       = {Tianqi Chen and
                  Thierry Moreau and
                  Ziheng Jiang and
                  Haichen Shen and
                  Eddie Q. Yan and
                  Leyuan Wang and
                  Yuwei Hu and
                  Luis Ceze and
                  Carlos Guestrin and
                  Arvind Krishnamurthy},
  title        = {{TVM:} End-to-End Optimization Stack for Deep Learning},
  journal      = {CoRR},
  volume       = {abs/1802.04799},
  year         = {2018},
  url          = {http://arxiv.org/abs/1802.04799},
  eprinttype    = {arXiv},
  eprint       = {1802.04799},
  timestamp    = {Sat, 17 Dec 2022 01:15:27 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1802-04799.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{exo,
author = {Ikarashi, Yuka and Bernstein, Gilbert Louis and Reinking, Alex and Genc, Hasan and Ragan-Kelley, Jonathan},
title = {Exocompilation for productive programming of hardware accelerators},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523446},
doi = {10.1145/3519939.3523446},
abstract = {High-performance kernel libraries are critical to exploiting accelerators and specialized instructions in many applications. Because compilers are difficult to extend to support diverse and rapidly-evolving hardware targets, and automatic optimization is often insufficient to guarantee state-of-the-art performance, these libraries are commonly still coded and optimized by hand, at great expense, in low-level C and assembly. To better support development of high-performance libraries for specialized hardware, we propose a new programming language, Exo, based on the principle of exocompilation: externalizing target-specific code generation support and optimization policies to user-level code. Exo allows custom hardware instructions, specialized memories, and accelerator configuration state to be defined in user libraries. It builds on the idea of user scheduling to externalize hardware mapping and optimization decisions. Schedules are defined as composable rewrites within the language, and we develop a set of effect analyses which guarantee program equivalence and memory safety through these transformations. We show that Exo enables rapid development of state-of-the-art matrix-matrix multiply and convolutional neural network kernels, for both an embedded neural accelerator and x86 with AVX-512 extensions, in a few dozen lines of code each.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {703–718},
numpages = {16},
keywords = {hardware accelerators, instruction abstraction, program optimization, scheduling, user-extensible backend \& scheduling, user-schedulable languages},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}